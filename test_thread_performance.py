#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çº¿ç¨‹æ•°æ€§èƒ½æµ‹è¯•å·¥å…·
ç”¨äºæ‰¾åˆ°æœ€ä½³çš„å¹¶å‘çº¿ç¨‹æ•°é…ç½®
"""

import time
import subprocess
import os
import json
import argparse
from datetime import datetime


def test_thread_performance(api_key, dataset_path, image_folder, model="gpt-4o", 
                          base_url="https://c-z0-api-01.hash070.com/v1", 
                          test_counts=[5, 10], thread_counts=[3, 5, 10, 15, 20]):
    """æµ‹è¯•ä¸åŒçº¿ç¨‹æ•°çš„æ€§èƒ½"""
    
    results = []
    
    print(f"å¼€å§‹çº¿ç¨‹æ•°æ€§èƒ½æµ‹è¯•")
    print(f"æ¨¡å‹: {model}")
    print(f"æµ‹è¯•çº¿ç¨‹æ•°: {thread_counts}")
    print(f"æ¯ä¸ªé…ç½®æµ‹è¯•æ ·æœ¬æ•°: {test_counts}")
    print("="*60)
    
    for test_count in test_counts:
        print(f"\næµ‹è¯•æ ·æœ¬æ•°: {test_count}")
        print("-" * 40)
        
        for thread_count in thread_counts:
            print(f"\næµ‹è¯• {thread_count} çº¿ç¨‹...")
            
            # æ¸…ç†ä¹‹å‰çš„æµ‹è¯•æ–‡ä»¶
            output_dir = f"thread_test_{thread_count}"
            if os.path.exists(output_dir):
                subprocess.run(['rm', '-rf', output_dir], check=True)
            
            cmd = [
                'python', 'openai_api_tester.py',
                '--api-key', api_key,
                '--dataset', dataset_path,
                '--base-url', base_url,
                '--model', model,
                '--image-folder', image_folder,
                '--output-dir', output_dir,
                '--multiprocess',
                '--max-workers', str(thread_count),
                '--test-mode',
                '--test-count', str(test_count),
                '--no-resume'  # ç¦ç”¨ç»­ä¼ ç¡®ä¿æ¯æ¬¡éƒ½æ˜¯å…¨æ–°æµ‹è¯•
            ]
            
            try:
                start_time = time.time()
                result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                end_time = time.time()
                
                duration = end_time - start_time
                samples_per_minute = test_count / (duration / 60) if duration > 0 else 0
                
                # å°è¯•è¯»å–ç»Ÿè®¡ä¿¡æ¯
                stats_file = os.path.join(output_dir, f"openai_{model.replace('-', '_')}_stats.json")
                tokens_used = 0
                api_calls = 0
                
                if os.path.exists(stats_file):
                    with open(stats_file, 'r') as f:
                        stats = json.load(f)
                        tokens_used = stats.get('total_tokens', 0)
                        api_calls = stats.get('total_api_calls', 0)
                
                result_data = {
                    'test_count': test_count,
                    'thread_count': thread_count,
                    'duration_seconds': duration,
                    'samples_per_minute': samples_per_minute,
                    'tokens_used': tokens_used,
                    'api_calls': api_calls,
                    'success': True,
                    'error': None
                }
                
                print(f"  âœ… æˆåŠŸ! ç”¨æ—¶: {duration:.1f}s, é€Ÿåº¦: {samples_per_minute:.1f} æ ·æœ¬/åˆ†é’Ÿ")
                
            except subprocess.TimeoutExpired:
                result_data = {
                    'test_count': test_count,
                    'thread_count': thread_count,
                    'duration_seconds': 300,
                    'samples_per_minute': 0,
                    'tokens_used': 0,
                    'api_calls': 0,
                    'success': False,
                    'error': 'Timeout'
                }
                print(f"  âŒ è¶…æ—¶!")
                
            except subprocess.CalledProcessError as e:
                result_data = {
                    'test_count': test_count,
                    'thread_count': thread_count,
                    'duration_seconds': 0,
                    'samples_per_minute': 0,
                    'tokens_used': 0,
                    'api_calls': 0,
                    'success': False,
                    'error': str(e)
                }
                print(f"  âŒ å¤±è´¥: {e}")
            
            results.append(result_data)
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            if os.path.exists(output_dir):
                subprocess.run(['rm', '-rf', output_dir])
            
            # ç­‰å¾…ä¸€ä¸‹é¿å…APIé™åˆ¶
            time.sleep(2)
    
    return results


def analyze_results(results):
    """åˆ†ææµ‹è¯•ç»“æœ"""
    print("\n" + "="*80)
    print("çº¿ç¨‹æ•°æ€§èƒ½æµ‹è¯•ç»“æœåˆ†æ")
    print("="*80)
    
    # æŒ‰æµ‹è¯•æ ·æœ¬æ•°åˆ†ç»„
    by_test_count = {}
    for result in results:
        test_count = result['test_count']
        if test_count not in by_test_count:
            by_test_count[test_count] = []
        by_test_count[test_count].append(result)
    
    for test_count, test_results in by_test_count.items():
        print(f"\næ ·æœ¬æ•° {test_count}:")
        print(f"{'çº¿ç¨‹æ•°':<8} {'æˆåŠŸ':<6} {'ç”¨æ—¶(s)':<10} {'é€Ÿåº¦(æ ·æœ¬/åˆ†)':<12} {'Token':<8}")
        print("-" * 50)
        
        successful_results = [r for r in test_results if r['success']]
        
        for result in test_results:
            status = "âœ…" if result['success'] else "âŒ"
            duration = f"{result['duration_seconds']:.1f}" if result['success'] else "N/A"
            speed = f"{result['samples_per_minute']:.1f}" if result['success'] else "N/A"
            tokens = f"{result['tokens_used']}" if result['success'] else "N/A"
            
            print(f"{result['thread_count']:<8} {status:<6} {duration:<10} {speed:<12} {tokens:<8}")
        
        if successful_results:
            # æ‰¾åˆ°æœ€ä½³çº¿ç¨‹æ•°
            best_result = max(successful_results, key=lambda x: x['samples_per_minute'])
            print(f"\nğŸ† æœ€ä½³é…ç½®: {best_result['thread_count']} çº¿ç¨‹")
            print(f"   é€Ÿåº¦: {best_result['samples_per_minute']:.1f} æ ·æœ¬/åˆ†é’Ÿ")
            print(f"   ç”¨æ—¶: {best_result['duration_seconds']:.1f} ç§’")
    
    # æ•´ä½“å»ºè®®
    all_successful = [r for r in results if r['success']]
    if all_successful:
        best_overall = max(all_successful, key=lambda x: x['samples_per_minute'])
        
        print(f"\nğŸ“Š æ•´ä½“æœ€ä½³é…ç½®:")
        print(f"   çº¿ç¨‹æ•°: {best_overall['thread_count']}")
        print(f"   æ ·æœ¬æ•°: {best_overall['test_count']}")
        print(f"   é€Ÿåº¦: {best_overall['samples_per_minute']:.1f} æ ·æœ¬/åˆ†é’Ÿ")
        
        # ç¨³å®šæ€§åˆ†æ
        thread_success_rate = {}
        for result in results:
            thread_count = result['thread_count']
            if thread_count not in thread_success_rate:
                thread_success_rate[thread_count] = {'success': 0, 'total': 0}
            
            thread_success_rate[thread_count]['total'] += 1
            if result['success']:
                thread_success_rate[thread_count]['success'] += 1
        
        print(f"\nğŸ“ˆ ç¨³å®šæ€§åˆ†æ:")
        print(f"{'çº¿ç¨‹æ•°':<8} {'æˆåŠŸç‡':<8}")
        print("-" * 20)
        for thread_count, stats in sorted(thread_success_rate.items()):
            success_rate = stats['success'] / stats['total'] * 100
            print(f"{thread_count:<8} {success_rate:.1f}%")


def main():
    parser = argparse.ArgumentParser(description='çº¿ç¨‹æ•°æ€§èƒ½æµ‹è¯•å·¥å…·')
    
    parser.add_argument('--api-key', required=True, help='APIå¯†é’¥')
    parser.add_argument('--dataset', required=True, help='æ•°æ®é›†CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--image-folder', required=True, help='å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--model', default='gpt-4o', help='ä½¿ç”¨çš„æ¨¡å‹åç§°')
    parser.add_argument('--base-url', default='https://c-z0-api-01.hash070.com/v1', help='APIåŸºç¡€URL')
    
    parser.add_argument('--thread-counts', nargs='*', type=int, default=[3, 5, 10, 15, 20],
                       help='è¦æµ‹è¯•çš„çº¿ç¨‹æ•°åˆ—è¡¨')
    parser.add_argument('--test-counts', nargs='*', type=int, default=[5, 10],
                       help='è¦æµ‹è¯•çš„æ ·æœ¬æ•°åˆ—è¡¨')
    
    args = parser.parse_args()
    
    print("å¼€å§‹çº¿ç¨‹æ•°æ€§èƒ½æµ‹è¯•...")
    print(f"è¿™å°†æµ‹è¯• {len(args.thread_counts)} ç§çº¿ç¨‹é…ç½® Ã— {len(args.test_counts)} ç§æ ·æœ¬æ•°")
    print(f"é¢„è®¡éœ€è¦ {len(args.thread_counts) * len(args.test_counts) * 2} åˆ†é’Ÿ")
    
    input("æŒ‰Enterç»§ç»­ï¼Œæˆ–Ctrl+Cå–æ¶ˆ...")
    
    results = test_thread_performance(
        api_key=args.api_key,
        dataset_path=args.dataset,
        image_folder=args.image_folder,
        model=args.model,
        base_url=args.base_url,
        test_counts=args.test_counts,
        thread_counts=args.thread_counts
    )
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = f"thread_performance_test_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    # åˆ†æç»“æœ
    analyze_results(results)


if __name__ == '__main__':
    main()
